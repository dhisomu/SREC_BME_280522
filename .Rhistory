0.7*nrow(ChemicalManufacturingProcess))
# generate the train data set
train = ChemicalManufacturingProcess[trainindices,1:13]
#Similarly store the rest of the observations into an object "test".
test = ChemicalManufacturingProcess[-trainindices,1:13]
#Execute the first model_1 multilinear model in the training set.
model_1 <-lm(Yield~.,data=train)
# Check the summary of model.
summary(model_1)
# Predict the house prices in the testing dataset
Predict_1 <- predict(model_1,test[,-1])
test$test_yeild <- Predict_1
# Accuracy of the predictions
# Calculate correlation
r <- cor(test$Yield,test$Yield)
# Accuracy of the predictions
# Calculate correlation
r <- cor(test$Yield,test$test_yeild)
# calculate R squared by squaring correlation
rsquared <- cor(test$Yield,test$test_yeild)^2
# check R-squared
rsquared
# Divide into training and test data set
#set the seed to 100, let's run it
set.seed(100)
# randomly generate row indices for train dataset
trainindices= sample(1:nrow(ChemicalManufacturingProcess),
0.7*nrow(ChemicalManufacturingProcess))
# generate the train data set
train = ChemicalManufacturingProcess[trainindices,1:13]
#Similarly store the rest of the observations into an object "test".
test = ChemicalManufacturingProcess[-trainindices,1:13]
#Execute the first model_1 multilinear model in the training set.
model_1 <-lm(Yield~.,data=train)
# Check the summary of model.
summary(model_1)
# Predict the house prices in the testing dataset
Predict_1 <- predict(model_1,test[,-1])
test$test_yeild <- Predict_1
# Accuracy of the predictions
# Calculate correlation
r <- cor(test$Yield,test$test_yeild)
# calculate R squared by squaring correlation
rsquared <- cor(test$Yield,test$test_yeild)^2
# check R-squared
rsquared
#Execute the first model_1 multilinear model in the training set.
model_1 <-lm(Yield~.^2,data=train)
# Check the summary of model.
summary(model_1)
# Predict the house prices in the testing dataset
Predict_1 <- predict(model_1,test[,-1])
test$test_yeild <- Predict_1
# Accuracy of the predictions
# Calculate correlation
r <- cor(test$Yield,test$test_yeild)
# calculate R squared by squaring correlation
rsquared <- cor(test$Yield,test$test_yeild)^2
# check R-squared
rsquared
#Execute the first model_1 multilinear model in the training set.
model_1 <-lm(Yield~.,data=train)
# Check the summary of model.
summary(model_1)
# Predict the house prices in the testing dataset
Predict_1 <- predict(model_1,test[,-1])
test$test_yeild <- Predict_1
# Accuracy of the predictions
# Calculate correlation
r <- cor(test$Yield,test$test_yeild)
# calculate R squared by squaring correlation
rsquared <- cor(test$Yield,test$test_yeild)^2
# check R-squared
rsquared
#Execute the first model_1 multilinear model in the training set.
model_1 <-lm(Yield~.^2,data=train)
# Check the summary of model.
summary(model_1)
# Predict the house prices in the testing dataset
Predict_1 <- predict(model_1,test[,-1])
test$test_yeild <- Predict_1
# Accuracy of the predictions
# Calculate correlation
r <- cor(test$Yield,test$test_yeild)
# calculate R squared by squaring correlation
rsquared <- cor(test$Yield,test$test_yeild)^2
# check R-squared
rsquared
#Execute the first model_1 multilinear model in the training set.
model_1 <-lm(Yield~.^2,data=train)
# Check the summary of model.
summary(model_1)
# Predict the house prices in the testing dataset
Predict_1 <- predict(model_1,test[,-1])
test$test_yeild <- Predict_1
# Accuracy of the predictions
# Calculate correlation
r <- cor(test$Yield,test$test_yeild)
# calculate R squared by squaring correlation
rsquared <- cor(test$Yield,test$test_yeild)^2
# check R-squared
rsquared
#Execute the first model_1 multilinear model in the training set.
model_1 <-lm(Yield~.^3,data=train)
# Check the summary of model.
summary(model_1)
# Predict the house prices in the testing dataset
Predict_1 <- predict(model_1,test[,-1])
test$test_yeild <- Predict_1
# Accuracy of the predictions
# Calculate correlation
r <- cor(test$Yield,test$test_yeild)
# calculate R squared by squaring correlation
rsquared <- cor(test$Yield,test$test_yeild)^2
# check R-squared
rsquared
#Execute the first model_1 multilinear model in the training set.
model_1 <-lm(Yield~.^3,data=train)
# Check the summary of model.
summary(model_1)
# Predict the house prices in the testing dataset
Predict_1 <- predict(model_1,test[,-1])
test$test_yeild <- Predict_1
# Accuracy of the predictions
# Calculate correlation
r <- cor(test$Yield,test$test_yeild)
# calculate R squared by squaring correlation
rsquared <- cor(test$Yield,test$test_yeild)^2
# check R-squared
rsquared
plot(model_1)
plot(test$Yield,test$test_yeild)
plot(test$Yield,test$test_yeild,ylim=c(0,100))
boxplot(train)
boxplot(scale(train))
#Execute the first model_1 multilinear model in the training set.
model_1 <-lm(Yield~.^3,data=scale(train))
##############
train[,2:13] <- scale(train[,2:13])
#Execute the first model_1 multilinear model in the training set.
model_1 <-lm(Yield~.,data=train)
# Check the summary of model.
summary(model_1)
test[,2:13] <- scale(test[,2:13])
# Predict the house prices in the testing dataset
Predict_1 <- predict(model_1,test[,-1])
test$test_yeild <- Predict_1
# Accuracy of the predictions
# Calculate correlation
r <- cor(test$Yield,test$test_yeild)
# calculate R squared by squaring correlation
rsquared <- cor(test$Yield,test$test_yeild)^2
# check R-squared
rsquared
#Execute the first model_1 multilinear model in the training set.
model_1 <-lm(Yield~.^3,data=train)
# Check the summary of model.
summary(model_1)
plot(model_1)
# Check the summary of model.
summary(model_1)
#plot(model_1)
# Predict the house prices in the testing dataset
Predict_1 <- predict(model_1,test[,-1])
test$test_yeild <- Predict_1
# Accuracy of the predictions
# Calculate correlation
r <- cor(test$Yield,test$test_yeild)
# calculate R squared by squaring correlation
rsquared <- cor(test$Yield,test$test_yeild)^2
# check R-squared
rsquared
# generate the train data set
train = ChemicalManufacturingProcess[trainindices,]
#Similarly store the rest of the observations into an object "test".
test = ChemicalManufacturingProcess[-trainindices,]
#Execute the first model_1 multilinear model in the training set.
model_1 <-lm(Yield~.,data=train)
# Check the summary of model.
summary(model_1)
# Predict the house prices in the testing dataset
Predict_1 <- predict(model_1,test[,-1])
test$test_yeild <- Predict_1
# Accuracy of the predictions
# Calculate correlation
r <- cor(test$Yield,test$test_yeild)
# calculate R squared by squaring correlation
rsquared <- cor(test$Yield,test$test_yeild)^2
# check R-squared
rsquared
# Predict the house prices in the testing dataset
Predict_1 <- predict(model_1,test[,-1])
#Execute the first model_1 multilinear model in the training set.
model_1 <-lm(Yield~.^2,data=train)
# Check the summary of model.
summary(model_1)
model_2 <- MASS::stepAIC(model_1,
scale = 1,
direction = "both")
summary(model_2)
# Predict the house prices in the testing dataset
Predict_2 <- predict(model_2,test[,-1])
test$test_yeild <- Predict_2
# Accuracy of the predictions
# Calculate correlation
r <- cor(test$Yield,test$test_yeild)
# calculate R squared by squaring correlation
rsquared <- cor(test$Yield,test$test_yeild)^2
# check R-squared
rsquared
summary(M2)
# Predict the house prices in the testing dataset
Predict_2 <- predict(model_2,test[,-1])
test$test_yeild <- Predict_2
# Accuracy of the predictions
# Calculate correlation
r <- cor(test$Yield,test$test_yeild)
# calculate R squared by squaring correlation
rsquared <- cor(test$Yield,test$test_yeild)^2
rsquared
#library(lattice)
#install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
data(ChemicalManufacturingProcess)
head(ChemicalManufacturingProcess)
#library(lattice)
#install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
data(ChemicalManufacturingProcess)
head(ChemicalManufacturingProcess)
? data(ChemicalManufacturingProcess)
colnames(ChemicalManufacturingProcess)
boxplot(ChemicalManufacturingProcess$Yield)
library(outliertree)
library(outliertree)
install.packages("outliertree")
library(outliertree)
library(pmmlTransformations)
install.packages("pmml")
library(pmmlTransformations)
iris
view(iris)
View(iris)
class(iris$Species)
class(iris$Sepal.Length)
df <- data("iris")
df_MD<-data.frame(colnames(df),paste(head(df),sep = ","),
sapply(df, function(x) class(x)),
colSums(is.na(df)),
sapply(df, function(x) length(unique(x))),
sapply(df, function(x) length(x))-sapply(df, function(x) length(unique(x))),
sapply(df, function(x) sum(duplicated(x))),row.names = NULL)
df
df <- iris
df_MD<-data.frame(colnames(df),paste(head(df),sep = ","),
sapply(df, function(x) class(x)),
colSums(is.na(df)),
sapply(df, function(x) length(unique(x))),
sapply(df, function(x) length(x))-sapply(df, function(x) length(unique(x))),
sapply(df, function(x) sum(duplicated(x))),row.names = NULL)
df_MD<-cbind(as.numeric(rownames(df_MD)),df_MD)
names(df_MD)<-c("col_Number","Var_Name","Head","class","NA_Count","Uniques","Duplicates","Duplicated")
View(df_MD)
df <- iris
df_MD<-data.frame(colnames(df),paste(head(df),sep = ","),
sapply(df, function(x) class(x)),
colSums(is.na(df)),
sapply(df, function(x) length(unique(x))),
sapply(df, function(x) length(x))-sapply(df, function(x) length(unique(x))),
sapply(df, function(x) length(x)),row.names = NULL)
df_MD<-cbind(as.numeric(rownames(df_MD)),df_MD)
names(df_MD)<-c("col_Number","Var_Name","Head","class","NA_Count","Uniques","Duplicates","Length")
View(df_MD)
df <- iris
df_MD<-data.frame(colnames(df),paste(head(df),sep = ","),
sapply(df, function(x) class(x)),
colSums(is.na(df)),
sapply(df, function(x) length(unique(x))),
sapply(df, function(x) length(x))-sapply(df, function(x) length(unique(x))),
sapply(df, function(x) length(x)),row.names = NULL)
df_MD<-cbind(as.numeric(rownames(df_MD)),df_MD)
names(df_MD)<-c("col_Number","Var_Name","Head","class","NA_Count","Uniques","Duplicates","Length")
View(df_MD)
df_MD
# no data quality issues
# EDA
boxplot(iris$Species ~.)
# no data quality issues
# EDA
boxplot(iris$Species ~ iris$Sepal.Length)
# no data quality issues
# EDA
boxplot(. ~ iris$Species)
# no data quality issues
# EDA
boxplot(iris$Sepal.Length ~ iris$Species)
boxplot(iris$Sepal.Width ~ iris$Species)
boxplot(iris$Petal.Length ~ iris$Species)
boxplot(iris$Petal.Width ~ iris$Species)
class(iris$Species)
irisLR<-lm(Sepal.Length~.,iris)
summary(irisLR)
library("MASS")
stepAIC(irisLR,direction = "both")
irisLR1 <- lm(formula = Sepal.Length ~ Sepal.Width + Petal.Length + Petal.Width +
Species, data = iris)
summary(irisLR1)
irisLR1 <- lm(formula = Sepal.Length ~ Sepal.Width
+ Petal.Length + Petal.Width + Species,
data = iris)
irisLR2 <- lm(formula = Sepal.Length ~ Sepal.Width
+ Petal.Length + Petal.Width,
data = iris)
summary(irisLR2)
install.packages("pmml")
# #Extensible Markup Language (XML) is a markup language
# that defines a set of rules for encoding documents in a format
# that is both human-readable and machine-readable.
library("pmml")
pmml(irisLR)
saveXML( pmml(irisLR), "IrisLR.xml" )
saveXML( pmml(irisLR2), "IrisLR2.xml" )
plot(irisLR)
library("MASS")
stepAIC(irisLR)
read.csv("https://github.com/dhisomu/PSG_PGCert_21/blob/7147db3cf9575fb3492b2ce5733ed3947f01f7f4/Data.csv")
qData <- read.csv("https://github.com/dhisomu/PSG_PGCert_21/blob/7147db3cf9575fb3492b2ce5733ed3947f01f7f4/Data.csv")
qData <- read.csv("https://github.com/dhisomu/PSG_PGCert_21/blob/7147db3cf9575fb3492b2ce5733ed3947f01f7f4/Data.csv",
sep = ",")
urlfile <- https://github.com/dhisomu/PSG_PGCert_21/blob/7147db3cf9575fb3492b2ce5733ed3947f01f7f4/Data.csv"
qData <- read.csv(url = urlfile,
sep = ",")
urlfile <- https://github.com/dhisomu/PSG_PGCert_21/blob/7147db3cf9575fb3492b2ce5733ed3947f01f7f4/Data.csv"
qData <- read.csv(url = urlfile,
sep = ",")
urlfile <- https://github.com/dhisomu/PSG_PGCert_21/blob/7147db3cf9575fb3492b2ce5733ed3947f01f7f4/Data.csv"
qData <- read.csv(url = urlfile,
sep = ",")
urlfile <- "https://github.com/dhisomu/PSG_PGCert_21/blob/7147db3cf9575fb3492b2ce5733ed3947f01f7f4/Data.csv"
View(qData)
urlfile <- "https://raw.githubusercontent.com/dhisomu/PSG_PGCert_21/main/Data.csv"
qData <- read.csv(url = urlfile,
sep = ",")
library (readr)
urlfile="https://raw.githubusercontent.com/dhisomu/PSG_PGCert_21/main/Data.csv"
mydata<-read_csv(url(urlfile))
mydata<- as.dataframe(read_csv(url(urlfile)))
mydata<- as.data.frame(read_csv(url(urlfile)))
View(mydata)
library (readr)
urlfile="https://raw.githubusercontent.com/dhisomu/PSG_PGCert_21/main/Data.csv"
mydata<- as.data.frame(read_csv(url(urlfile)))
View(mydata)
# Importing the dataset
dataset = read.csv(url(urlfile))
# Taking care of missing data
dataset$Age = ifelse(is.na(dataset$Age),
ave(dataset$Age, FUN = function(x) mean(x, na.rm = TRUE)),
dataset$Age)
View(dataset)
# Importing the dataset
dataset = read.csv(url(urlfile))
View(dataset)
library(AppliedPredictiveModeling)
data(solubility)
colnames(solubility)
colnames(data(solubility))
View(data(solubility))
library(lattice)
xyplot(solTrainY ~ solTrainX$MolWeight, type = c("p", "g"),
ylab = "Solubility (log)",
main = "(a)",
xlab = "Molecular Weight")
# Data Preprocessing
library (readr)
urlfile="https://raw.githubusercontent.com/dhisomu/PSG_PGCert_21/main/Data.csv"
dataset <- as.data.frame(read_csv(url(urlfile)))
View(dataset)
setwd("/cloud/project/Machine Learning A-Z (Codes and Datasets)/Part 1 - Data Preprocessing/Section 2 -------------------- Part 1 - Data Preprocessing --------------------/R")
setwd("/cloud/project/Machine Learning A-Z (Codes and Datasets)/Part 1 - Data Preprocessing/Section 2 -------------------- Part 1 - Data Preprocessing --------------------/R")
# Importing the dataset
dataset = read.csv('Data.csv')
dataset <- as.data.frame(read_csv(url(urlfile)))
rm(dataset)
# Importing the dataset
dataset = read.csv('Data.csv')
df <- dataset
df_MD<-data.frame(colnames(df),paste(head(df),sep = ","),
sapply(df, function(x) class(x)),
colSums(is.na(df)),
sapply(df, function(x) length(unique(x))),
sapply(df, function(x) length(x))-sapply(df, function(x) length(unique(x))),
sapply(df, function(x) length(x)),row.names = NULL)
df_MD<-cbind(as.numeric(rownames(df_MD)),df_MD)
names(df_MD)<-c("col_Number","Var_Name","Head","class","NA_Count","Uniques","Duplicates","Length")
View(df_MD)
is.na(dataset$Age)
# Taking care of missing data
dataset$Age = ifelse(is.na(dataset$Age),
ave(dataset$Age, FUN = function(x) mean(x, na.rm = TRUE)),
dataset$Age)
is.na(dataset$Age)
is.na(dataset$Salary)
dataset$Salary = ifelse(is.na(dataset$Salary),
ave(dataset$Salary, FUN = function(x) mean(x, na.rm = TRUE)),
dataset$Salary)
is.na(dataset$Salary)
class(dataset$Country)
# Encoding categorical data
dataset$Country = factor(dataset$Country,
levels = c('France', 'Spain', 'Germany'),
labels = c(1, 2, 3))
class(dataset$Country)
class(as.numeric(dataset$Country))
dataset$Purchased = factor(dataset$Purchased,
levels = c('No', 'Yes'),
labels = c(0, 1))
# Splitting the dataset into the Training set and Test set
# install.packages('caTools')
library(caTools)
set.seed(123)
set.seed(123)
split = sample.split(dataset$DependentVariable, SplitRatio = 0.8)
#split = sample.split(dataset$DependentVariable, SplitRatio = 0.8)
split = sample.split(dataset$Purchased, SplitRatio = 0.8) #changeME#
split
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
View(test_set)
View(training_set)
# Feature Scaling
training_set_s = scale(training_set)
# Feature Scaling
training_set_s = scale(as.numeric(training_set))
#split = sample.split(dataset$DependentVariable, SplitRatio = 0.8)
split = sample.split(dataset$Purchased, SplitRatio = 0.8) #changeME#
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
# Feature Scaling
training_set_s = scale(as.numeric(training_set))
# Feature Scaling
training_set_s = scale(training_set)
View(training_set)
# Feature Scaling
training_set_s = scale(training_set)
summary(training_set)
dataset_m <- as.numeric(dataset)
dataset_m <- dataset
dataset_m$Country <- as.numeric(dataset$Country)
dataset_m$Purchased <- as.numeric(dataset$Purchased)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
summary(training_set)
training_set = subset(dataset_m, split == TRUE)
test_set = subset(dataset_m, split == FALSE)
summary(training_set)
training_set_s = scale(training_set)
test_set_s = scale(test_set)
View(training_set_s)
View(training_set)
atr(training_set_s,.scale)
attr(training_set_s, "scaled:center")
attr(training_set_s, "scaled:scale")
-1.42857869 / 7.9
-1.42857869 * 7.9
-11.28577+38.34722
-1.42857869 * 7.943015
38.34722 -11.34722
attr(training_set_s, "scaled:center")
attr(training_set_s, "scaled:scale")
boxplot(training_set)
boxplot(training_set_s)
par(mfrow=c(2,1))
boxplot(training_set)
boxplot(training_set_s)
par(mfrow=c(2,1))
boxplot(training_set)
par(mfrow=c(2,1))
boxplot(training_set)
par(mfrow=c(2,1))
boxplot(training_set)
boxplot(training_set_s)
boxplot(training_set)
boxplot(training_set_s)
library(dplyr)
training_set_s <- scale(training_set)
train_center <- attr(training_set_s, "scaled:center")
train_scale <- attr(training_set_s, "scaled:scale")
test_set_s <- normalize(test_set,train_center,train_scale)
normalize <- function(newdataf, dataf_center,dataf_scale){
normalizeddataf <- newdataf
for (n in names(newdataf)){
normalizeddataf[,n] <-
(newdataf[,n] - dataf_center[n]) /  dataf_scale[n]
}
return(normalizeddataf)
}
test_set_s <- normalize(test_set,train_center,train_scale)
View(test_set_s)
par(mfrow=c(2,1))
boxplot(training_set)
boxplot(training_set_s)
install.packages("git")
reticulate::repl_python()
# Multiple Linear Regression
import numpy as np
# Importing the libraries
Y
reticulate::repl_python()
import numpy as np
y
reticulate::repl_python()
